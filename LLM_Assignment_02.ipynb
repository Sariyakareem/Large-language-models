{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision transformers datasets matplotlib pandas scikit-learn wordcloud\n",
    "!pip install --upgrade --force-reinstall fsspec datasets"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- IMPORTS ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- PLOT STYLE ---\n",
    "plt.style.use('seaborn-v0_8-bright')\n",
    "\n",
    "# --- DEVICE SETUP ---\n",
    "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\", dev)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- LOAD AG NEWS DATASET ---\n",
    "news_raw = load_dataset(\"ag_news\")\n",
    "news_df = pd.concat([pd.DataFrame(news_raw['train']), pd.DataFrame(news_raw['test'])], ignore_index=True)\n",
    "news_df = news_df.sample(frac=1, random_state=321).reset_index(drop=True)\n",
    "\n",
    "# --- FOR QUICK TRAINING, TAKE A SAMPLE SUBSET ---\n",
    "small_df, small_test = train_test_split(\n",
    "    news_df, train_size=4000, test_size=800,\n",
    "    stratify=news_df['label'], random_state=321\n",
    ")\n",
    "print(small_df['label'].value_counts(), '\\n', small_test['label'].value_counts())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- VISUALIZE LABEL DISTRIBUTION ---\n",
    "plt.figure(figsize=(5,3))\n",
    "label_names = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
    "small_df['label'].value_counts().sort_index().plot(kind='bar', color=['#ee964b', '#35a7ff', '#8ac926', '#ff595e'], edgecolor='black')\n",
    "plt.xticks(ticks=range(4), labels=label_names, rotation=20)\n",
    "plt.title('AG News - Label Distribution', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- VISUALIZE NEWS TITLE LENGTHS ---\n",
    "small_df['text_len'] = small_df['text'].apply(lambda x: len(x.split()))\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.hist(small_df['text_len'], bins=30, color='#b983ff', edgecolor='#22223b', alpha=0.83)\n",
    "plt.title('Distribution of News Title Lengths', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Words in Title')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- WORD CLOUDS FOR EACH CLASS ---\n",
    "for class_id, class_name, cmap in zip(range(4), label_names, ['cividis', 'plasma', 'summer', 'viridis']):\n",
    "    text_blob = \" \".join(small_df[small_df['label']==class_id]['text'])\n",
    "    wc = WordCloud(width=600, height=250, background_color='white', colormap=cmap).generate(text_blob)\n",
    "    plt.figure(figsize=(7,2.5))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Word Cloud: {class_name}', fontsize=12, color='#14213d')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- DATA PREP FOR MODEL ---\n",
    "X_train = small_df['text'].tolist()\n",
    "y_train = small_df['label'].tolist()\n",
    "X_eval = small_test['text'].tolist()\n",
    "y_eval = small_test['label'].tolist()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- CUSTOM DATASET CLASS ---\n",
    "class NewsBertSet(Dataset):\n",
    "    def __init__(self, texts, targets, tokenizer, maxlen):\n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.maxlen = maxlen\n",
    "    def __len__(self): return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.maxlen,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        out = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        out['labels'] = torch.tensor(self.targets[idx], dtype=torch.long)\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- TOKENIZER & DATALOADERS ---\n",
    "ag_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "max_len = 40\n",
    "\n",
    "ds_train = NewsBertSet(X_train, y_train, ag_tokenizer, max_len)\n",
    "ds_eval = NewsBertSet(X_eval, y_eval, ag_tokenizer, max_len)\n",
    "\n",
    "loader_train = DataLoader(ds_train, batch_size=20, shuffle=True)\n",
    "loader_eval = DataLoader(ds_eval, batch_size=20)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- MODEL, OPTIMIZER, LOSS ---\n",
    "topic_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4)\n",
    "topic_model = topic_model.to(dev)\n",
    "optim_news = AdamW(topic_model.parameters(), lr=2e-5)\n",
    "loss_news = nn.CrossEntropyLoss()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- SHOW SAMPLE INPUTS ---\n",
    "print(\"\\nAG News test samples and labels:\\n\")\n",
    "for k in range(3):\n",
    "    print(f\"Title: {X_eval[k][:100]}...\")\n",
    "    print(f\"True Label: {y_eval[k]} ({label_names[y_eval[k]]})\")\n",
    "    print()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- TRAINING LOOP ---\n",
    "epochs_news = 10\n",
    "news_losses = []\n",
    "\n",
    "for ep in range(epochs_news):\n",
    "    topic_model.train()\n",
    "    ep_loss = 0\n",
    "    for batch in loader_train:\n",
    "        ids = batch['input_ids'].to(dev)\n",
    "        mask = batch['attention_mask'].to(dev)\n",
    "        labs = batch['labels'].to(dev)\n",
    "        optim_news.zero_grad()\n",
    "        output = topic_model(input_ids=ids, attention_mask=mask, labels=labs)\n",
    "        loss = output.loss\n",
    "        loss.backward()\n",
    "        optim_news.step()\n",
    "        ep_loss += loss.item()\n",
    "    avg = ep_loss / len(loader_train)\n",
    "    news_losses.append(avg)\n",
    "    print(f\"Epoch {ep+1}/{epochs_news} | Loss: {avg:.4f}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- PLOT TRAINING LOSS ---\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(range(1, epochs_news+1), news_losses, marker='*', linestyle='-', color='#ef476f', linewidth=2.2)\n",
    "plt.title('Training Loss per Epoch (AG News)', fontsize=13, fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, linestyle=':', alpha=0.55)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- EVALUATION ---\n",
    "topic_model.eval()\n",
    "news_preds, news_true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loader_eval:\n",
    "        ids = batch['input_ids'].to(dev)\n",
    "        mask = batch['attention_mask'].to(dev)\n",
    "        labs = batch['labels'].to(dev)\n",
    "        outs = topic_model(input_ids=ids, attention_mask=mask)\n",
    "        preds = torch.argmax(outs.logits, dim=1)\n",
    "        news_preds.extend(preds.cpu().numpy())\n",
    "        news_true.extend(labs.cpu().numpy())\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "acc_news = accuracy_score(news_true, news_preds)\n",
    "f1_news = f1_score(news_true, news_preds, average='weighted')\n",
    "print(f\"\\nAG News Test Accuracy: {acc_news:.4f}\")\n",
    "print(f\"AG News Test F1 Score: {f1_news:.4f}\")\n",
    "\n",
    "cm_news = confusion_matrix(news_true, news_preds)\n",
    "disp_news = ConfusionMatrixDisplay(confusion_matrix=cm_news, display_labels=label_names)\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "disp_news.plot(cmap='YlGnBu', ax=ax, colorbar=False)\n",
    "plt.title('AG News Topic Confusion Matrix', fontsize=12, color='#2d3142')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- SHOW PREDICTIONS ---\n",
    "print(\"\\nPredictions on Test Samples:\\n\")\n",
    "for k in range(5):\n",
    "    print(f\"Title: {X_eval[k][:100]}...\")\n",
    "    print(f\"True: {label_names[y_eval[k]]} | Predicted: {label_names[news_preds[k]]}\")\n",
    "    print()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}